{
  "api": "2.0",
  "content": {
    "html": "",
    "markdown": "Liu et al., 2024). Given these constraints, recent\nstudies probe into utilizing LLMs to automatically\ngenerate synthetic instruction data (Whitehouse\net al., 2023; Dai et al., 2023; Taori et al., 2023b).\nSpecifically, these approaches involve prompting\npowerful LLMs with limited seed data to gener-\nate additional synthetic data. These data are sub-\nsequently employed to fine-tune smaller models,\naiming to transfer knowledge to small LLMs and\nenhance their performance (Wang et al., 2023a).\nLeveraging LLMs to generate data can signifi-\ncantly reduce the costs and time for data curation\n(Liu et al., 2024), while simultaneously improv-\ning the efficacy of the fine-tuned models for des-\nignated downstream tasks (Yang et al., 2020; Puri\net al., 2020; Guo et al., 2023; Samuel et al., 2023;\nSchlegel et al., 2023).\n\n# 3 LLMOps Pipeline: LlamaDuo\n\nIn this section, we elaborate on the details of the\nproposed LlamaDuo, which are depicted in Fig-\nure 1. This LLMOps pipeline aims to ensure\nservice LLMs continuity by transitioning knowl-\nedge and abilities from service-oriented LLMs to\nsmaller, locally manageable LLMs without the\nneed for human intervention.\n\n# 3.1 Coverage Dataset\n\nUsers interact with service LLMs through prompt\nengineering efforts. The historical trials composed\nof the user input prompt and the responses of ser-\nvice LLMs, and potential errors will be recorded\nand saved in local storage. Subsequently, users an-\nnotate and collect the most satisfied prompt and\nresponse pairs conformed with their real-world\nuse cases. The resulting instruction dataset is\ntermed as coverage dataset, denoted as D(0) =\n(IO R(0)}N=1, and split as train and test subsets\n,\nby ratio \u2300. Here, \u5de5(0) denotes the i-th instruc-\ntion (prompt) in D(0) , R(10) is the corresponding\nresponse for the i-th instruction, and N is the num-\nber of samples in D(0). Since coverage dataset is of\nhigh quality and satisfying the user's intent in real-\nworld context, the train subsets I Dtrain I: = \u2300 \u00b7 N\nwill be served as seeds for synthetic datasets gener-\nation, while the test subset I Dtest |= (1 - \u2300) \u00b7 N\nis reserved for performance evaluation of the fine-\ntuned local LLMs.\n\n3.2 Fine-tuning\n\nTo efficiently and effectively adapt the local model\nto specific downstream task(s), we finetune the lo-\ncal LLM with the supervised learning paradigm on\nhigh-quality instruction data. At the initial cycli-\ncality of the pipeline, the selected local LLM is\nfine-tuned on the train subsets Dtrain of the COV-\nerage dataset, obtaining the fine-tuned model \ufffd(0).\nAt subsequent cyclicality t, if the performance of\nfine-tuned model does not reach or surpass the\npredetermined evaluation threshold E of specific\ntasks, the local LLM \ufffd(t) will be continuously fine-\ntuned on the increasing number of synthetic data\n{Dsynth, Dsynth, \u00b7 \u00b7 * , D(t-1th} generated from ser-\nvice LLMs with Dtrain as seed dataset. Conse-\nquently, when t \u2265 1, the objective of the fine-\ntuning phase can be formulated as\n\n$$\\begin{array}{l}{{{\\mathcal Z}_{\\mathrm{SFT}}(\\pi^{(t)},D^{(t)})=-\\mathrm{l}\\Xi\\left[\\log{\\cal P}_{\\pi^{(t-1)}}(\\mathcal{Q}^{(t)}\\mid\\mathcal{L}^{(t)})\\right],}}\\\\ {{{\\cal D}_{t r a i n.}}}\\end{array}$$\n\n3.3 Batch Inference\n\nAfter the fine-tuning stage, the fine-tuned local\nmodel is prompted with prompts \u5de5(0) sampled from\nthe test subsets Dtest of the coverage dataset to\nproduce corresponding response R ~ \u5143(t) (R(0) I\nI(0)). To improve the diversity and robustness\nof responses, the local model generates a batch\nof K responses {R1, R2, \u00b7 \u00b7 \u00b7 , RK} for each given\nprompt I(0). Totally, it will construct prompt and\nresponses pairs {(\u24cf.\u24ea) Ri)}(1-\u2300)-N-K \u00b7 Formally,\n,\n\n$$\\hat{\\cal Q}_{k}\\sim\\pi^{(t)}({\\cal Q}^{(0)}\\mid\\mathcal L^{(0)}),$$\n\nwhere k E {1,2, . . \u00b7 , K}, \u5de5(0) ~ D (0)\ntest\u00b7\n\n3.4 Evaluation\n\n(2)\n\nIn the evaluation stage, we employ \"service\nLLMs-as-judge\", , denoted as ELLM(\u00b7), to con-\nduct performance evaluation of local model on\n{(I,0) , Ri)}(1-\u2300)-N-K \u00b7 Following the works\n(Zheng et al., 2024; Yuan et al., 2024), the\nservice LLMs evaluate each response triple\n(\u5de5(0) R, R(0)), comprising prompt, the corre-\nsponding generated response, and the ground truth,\nby M times with pairwise comparison and single\nanswer grading strategies. This evaluation process\nguarantees the trustworthy and reduces the inher-\nent bias of results. Moreover, when employing",
    "text": ""
  },
  "elements": [
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Liu et al., 2024). Given these constraints, recent\nstudies probe into utilizing LLMs to automatically\ngenerate synthetic instruction data (Whitehouse\net al., 2023; Dai et al., 2023; Taori et al., 2023b).\nSpecifically, these approaches involve prompting\npowerful LLMs with limited seed data to gener-\nate additional synthetic data. These data are sub-\nsequently employed to fine-tune smaller models,\naiming to transfer knowledge to small LLMs and\nenhance their performance (Wang et al., 2023a).\nLeveraging LLMs to generate data can signifi-\ncantly reduce the costs and time for data curation\n(Liu et al., 2024), while simultaneously improv-\ning the efficacy of the fine-tuned models for des-\nignated downstream tasks (Yang et al., 2020; Puri\net al., 2020; Guo et al., 2023; Samuel et al., 2023;\nSchlegel et al., 2023).",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1157,
          "y": 0.0857
        },
        {
          "x": 0.4909,
          "y": 0.0857
        },
        {
          "x": 0.4909,
          "y": 0.3589
        },
        {
          "x": 0.1157,
          "y": 0.3589
        }
      ],
      "id": 0,
      "page": 1
    },
    {
      "category": "heading1",
      "content": {
        "html": "",
        "markdown": "# 3 LLMOps Pipeline: LlamaDuo",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1158,
          "y": 0.3851
        },
        {
          "x": 0.4106,
          "y": 0.3851
        },
        {
          "x": 0.4106,
          "y": 0.4027
        },
        {
          "x": 0.1158,
          "y": 0.4027
        }
      ],
      "id": 1,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "In this section, we elaborate on the details of the\nproposed LlamaDuo, which are depicted in Fig-\nure 1. This LLMOps pipeline aims to ensure\nservice LLMs continuity by transitioning knowl-\nedge and abilities from service-oriented LLMs to\nsmaller, locally manageable LLMs without the\nneed for human intervention.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.116,
          "y": 0.4212
        },
        {
          "x": 0.4907,
          "y": 0.4212
        },
        {
          "x": 0.4907,
          "y": 0.5339
        },
        {
          "x": 0.116,
          "y": 0.5339
        }
      ],
      "id": 2,
      "page": 1
    },
    {
      "category": "heading1",
      "content": {
        "html": "",
        "markdown": "# 3.1 Coverage Dataset",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1155,
          "y": 0.56
        },
        {
          "x": 0.3016,
          "y": 0.56
        },
        {
          "x": 0.3016,
          "y": 0.5765
        },
        {
          "x": 0.1155,
          "y": 0.5765
        }
      ],
      "id": 3,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Users interact with service LLMs through prompt\nengineering efforts. The historical trials composed\nof the user input prompt and the responses of ser-\nvice LLMs, and potential errors will be recorded\nand saved in local storage. Subsequently, users an-\nnotate and collect the most satisfied prompt and\nresponse pairs conformed with their real-world\nuse cases. The resulting instruction dataset is\ntermed as coverage dataset, denoted as D(0) =\n(IO R(0)}N=1, and split as train and test subsets\n,\nby ratio \u2300. Here, \u5de5(0) denotes the i-th instruc-\ntion (prompt) in D(0) , R(10) is the corresponding\nresponse for the i-th instruction, and N is the num-\nber of samples in D(0). Since coverage dataset is of\nhigh quality and satisfying the user's intent in real-\nworld context, the train subsets I Dtrain I: = \u2300 \u00b7 N\nwill be served as seeds for synthetic datasets gener-\nation, while the test subset I Dtest |= (1 - \u2300) \u00b7 N\nis reserved for performance evaluation of the fine-\ntuned local LLMs.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1151,
          "y": 0.589
        },
        {
          "x": 0.492,
          "y": 0.589
        },
        {
          "x": 0.492,
          "y": 0.9223
        },
        {
          "x": 0.1151,
          "y": 0.9223
        }
      ],
      "id": 4,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "3.2 Fine-tuning",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5115,
          "y": 0.0857
        },
        {
          "x": 0.6505,
          "y": 0.0857
        },
        {
          "x": 0.6505,
          "y": 0.1013
        },
        {
          "x": 0.5115,
          "y": 0.1013
        }
      ],
      "id": 5,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "To efficiently and effectively adapt the local model\nto specific downstream task(s), we finetune the lo-\ncal LLM with the supervised learning paradigm on\nhigh-quality instruction data. At the initial cycli-\ncality of the pipeline, the selected local LLM is\nfine-tuned on the train subsets Dtrain of the COV-\nerage dataset, obtaining the fine-tuned model \ufffd(0).\nAt subsequent cyclicality t, if the performance of\nfine-tuned model does not reach or surpass the\npredetermined evaluation threshold E of specific\ntasks, the local LLM \ufffd(t) will be continuously fine-\ntuned on the increasing number of synthetic data\n{Dsynth, Dsynth, \u00b7 \u00b7 * , D(t-1th} generated from ser-\nvice LLMs with Dtrain as seed dataset. Conse-\nquently, when t \u2265 1, the objective of the fine-\ntuning phase can be formulated as",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5112,
          "y": 0.1065
        },
        {
          "x": 0.8859,
          "y": 0.1065
        },
        {
          "x": 0.8859,
          "y": 0.3722
        },
        {
          "x": 0.5112,
          "y": 0.3722
        }
      ],
      "id": 6,
      "page": 1
    },
    {
      "category": "equation",
      "content": {
        "html": "",
        "markdown": "$$\\begin{array}{l}{{{\\mathcal Z}_{\\mathrm{SFT}}(\\pi^{(t)},D^{(t)})=-\\mathrm{l}\\Xi\\left[\\log{\\cal P}_{\\pi^{(t-1)}}(\\mathcal{Q}^{(t)}\\mid\\mathcal{L}^{(t)})\\right],}}\\\\ {{{\\cal D}_{t r a i n.}}}\\end{array}$$",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5104,
          "y": 0.3803
        },
        {
          "x": 0.8863,
          "y": 0.3803
        },
        {
          "x": 0.8863,
          "y": 0.4605
        },
        {
          "x": 0.5104,
          "y": 0.4605
        }
      ],
      "id": 7,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "3.3 Batch Inference",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5117,
          "y": 0.4688
        },
        {
          "x": 0.6824,
          "y": 0.4688
        },
        {
          "x": 0.6824,
          "y": 0.4843
        },
        {
          "x": 0.5117,
          "y": 0.4843
        }
      ],
      "id": 8,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "After the fine-tuning stage, the fine-tuned local\nmodel is prompted with prompts \u5de5(0) sampled from\nthe test subsets Dtest of the coverage dataset to\nproduce corresponding response R ~ \u5143(t) (R(0) I\nI(0)). To improve the diversity and robustness\nof responses, the local model generates a batch\nof K responses {R1, R2, \u00b7 \u00b7 \u00b7 , RK} for each given\nprompt I(0). Totally, it will construct prompt and\nresponses pairs {(\u24cf.\u24ea) Ri)}(1-\u2300)-N-K \u00b7 Formally,\n,",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5099,
          "y": 0.4892
        },
        {
          "x": 0.8843,
          "y": 0.4892
        },
        {
          "x": 0.8843,
          "y": 0.6393
        },
        {
          "x": 0.5099,
          "y": 0.6393
        }
      ],
      "id": 9,
      "page": 1
    },
    {
      "category": "equation",
      "content": {
        "html": "",
        "markdown": "$$\\hat{\\cal Q}_{k}\\sim\\pi^{(t)}({\\cal Q}^{(0)}\\mid\\mathcal L^{(0)}),$$",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.6071,
          "y": 0.6478
        },
        {
          "x": 0.7831,
          "y": 0.6478
        },
        {
          "x": 0.7831,
          "y": 0.6665
        },
        {
          "x": 0.6071,
          "y": 0.6665
        }
      ],
      "id": 10,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "where k E {1,2, . . \u00b7 , K}, \u5de5(0) ~ D (0)\ntest\u00b7",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5099,
          "y": 0.6783
        },
        {
          "x": 0.8073,
          "y": 0.6783
        },
        {
          "x": 0.8073,
          "y": 0.6977
        },
        {
          "x": 0.5099,
          "y": 0.6977
        }
      ],
      "id": 11,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "3.4 Evaluation",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5112,
          "y": 0.7068
        },
        {
          "x": 0.6444,
          "y": 0.7068
        },
        {
          "x": 0.6444,
          "y": 0.722
        },
        {
          "x": 0.5112,
          "y": 0.722
        }
      ],
      "id": 12,
      "page": 1
    },
    {
      "category": "caption",
      "content": {
        "html": "",
        "markdown": "(2)",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.8585,
          "y": 0.6506
        },
        {
          "x": 0.8835,
          "y": 0.6506
        },
        {
          "x": 0.8835,
          "y": 0.6664
        },
        {
          "x": 0.8585,
          "y": 0.6664
        }
      ],
      "id": 13,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "In the evaluation stage, we employ \"service\nLLMs-as-judge\", , denoted as ELLM(\u00b7), to con-\nduct performance evaluation of local model on\n{(I,0) , Ri)}(1-\u2300)-N-K \u00b7 Following the works\n(Zheng et al., 2024; Yuan et al., 2024), the\nservice LLMs evaluate each response triple\n(\u5de5(0) R, R(0)), comprising prompt, the corre-\nsponding generated response, and the ground truth,\nby M times with pairwise comparison and single\nanswer grading strategies. This evaluation process\nguarantees the trustworthy and reduces the inher-\nent bias of results. Moreover, when employing",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5113,
          "y": 0.7281
        },
        {
          "x": 0.8846,
          "y": 0.7281
        },
        {
          "x": 0.8846,
          "y": 0.9229
        },
        {
          "x": 0.5113,
          "y": 0.9229
        }
      ],
      "id": 14,
      "page": 1
    }
  ],
  "merged_elements": [],
  "model": "document-parse-250404",
  "ocr": true,
  "usage": {
    "pages": 1
  }
}