{
  "api": "2.0",
  "content": {
    "html": "",
    "markdown": "downstream tasks, providing a promising research\ndirection to maintain cloud-based LLMs\u2019 service\ncontinuity in constrained environments.\n\n# Limitations\n\nWhile our LlamaDuo pipeline presents a promising\nsolution for migrating capabilities from service-\noriented LLMs to smaller local models, as de-\npicted in Table 1, several limitations must be\nacknowledged. First, the reliance on synthetic\ndatasets generated by the service LLM may in-\ntroduce biases and safety issues inherent in the\noriginal model, potentially affecting the fine-tuned\nmodel\u2019s performance on specific tasks or datasets\n(Liu et al., 2024). Additionally, the effectiveness of\nthe pipeline in transferring knowledge is contingent\nupon the quality and diversity of the synthetic data\ngenerated. If the data does not adequately cover the\nnecessary scope, the fine-tuned model may strug-\ngle with tasks outside of the provided examples\n(Razeghi et al., 2022; Kandpal et al., 2023). Fur-\nthermore, the iterative fine-tuning process, while\nbeneficial for performance enhancement, can be\ncomputationally intensive and time-consuming, po-\ntentially offsetting some gains in model efficiency,\ncost, and affordability. Another limitation is the\npotential plateau in performance gains after several\nSFT iterations, which could necessitate alternative\nstrategies for further improvement, e.g., reinforce-\nment learning (RL) (Ouyang et al., 2022; Rafailov\net al., 2023). Lastly, the pipeline assumes access\nto the service LLM for data generation, which may\nnot always be feasible due to proprietary restric-\ntions or API access limitations.\n\n# Ethical Considerations\n\nOur work introduces several ethical considerations\nthat require careful examination. Primarily, the pro-\ncess of generating synthetic datasets raises ques-\ntions about data privacy and security, especially if\nthe data contains sensitive or proprietary informa-\ntion. There is a risk that such data, if not properly\nanonymized and secured, could lead to privacy vi-\nolations or unauthorized data exposure (Liu et al.,\n2024; Das et al., 2025). Moreover, the transfer of\nbiases from the service LLM to the smaller model\ncould perpetuate or even exacerbate existing biases,\nleading to unfair or discriminatory outcomes in cer-\ntain applications. It is crucial to implement robust\nbias detection and mitigation strategies within the\npipeline to safeguard against these risks. Addition-\n\nally, the use of proprietary models for generating\nsynthetic data necessitates transparency regarding\ndata handling practices and the potential limitations\nof the resultant models (Wang et al., 2023b).\n\nBroader Impact\n\nBeyond the immediate focus of this paper, we\nbelieve that the introduction of the LlamaDuo\npipeline has the potential to significantly impact\nthe landscape of LLMs deployment, particularly in\nenvironments with constrained resources or strin-\ngent privacy requirements. By enabling the mi-\ngration of capabilities from large service-oriented\nLLMs to smaller, locally manageable models,\nthe pipeline empowers organizations to maintain\nLLMs functionalities independently of external ser-\nvice providers, enhancing operational resilience\nand reducing dependency. This can lead to in-\ncreased accessibility to advanced LLMs for smaller\nentities or those operating in regions with limited\ninternet connectivity.\n\nAcknowledgements\n\nJing Tang\u2019s work is partially supported by Na-\ntional Key R&D Program of China under Grant\nNo. 2024YFA1012700 and No. 2023YFF0725100,\nby the National Natural Science Foundation of\nChina (NSFC) under Grant No. 62402410 and\nNo. U22B2060, by Guangdong Provincial Project\n(No. 2023QN10X025), by Guangdong Basic and\nApplied Basic Research Foundation under Grant\nNo. 2023A1515110131, by Guangzhou Municipal\nScience and Technology Bureau under Grant No.\n2024A04J4454, by Guangzhou Municipal Educa-\ntion Bureau (No. 2024312263), by Nansha District\nProject (No. 2023ZD022), and by Guangzhou In-\ndustrial Information and Intelligent Key Labora-\ntory Project (No. 2024A03J0628) and Guangzhou\nMunicipal Key Laboratory of Financial Technol-\nogy Cutting-Edge Research (No. 2024A03J0630).\nThis work is supported by IITP grant funded by\nthe Korea government(MSIT)[RS-2023-00215959,\nDevelopment of Access Agnostic wired and wire-\nless integrated optical access technology].\n\nReferences\n\nNazmiye Ceren Abay, Yan Zhou, Murat Kantarcioglu,\nBhavani Thuraisingham, and Latanya Sweeney. 2019.\nPrivacy preserving synthetic data release using deep\nlearning. In Machine Learning and Knowledge\nDiscovery in Databases: European Conference,",
    "text": ""
  },
  "elements": [
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "downstream tasks, providing a promising research\ndirection to maintain cloud-based LLMs\u2019 service\ncontinuity in constrained environments.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1156,
          "y": 0.0861
        },
        {
          "x": 0.4886,
          "y": 0.0861
        },
        {
          "x": 0.4886,
          "y": 0.134
        },
        {
          "x": 0.1156,
          "y": 0.134
        }
      ],
      "id": 0,
      "page": 1
    },
    {
      "category": "heading1",
      "content": {
        "html": "",
        "markdown": "# Limitations",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1156,
          "y": 0.147
        },
        {
          "x": 0.2211,
          "y": 0.147
        },
        {
          "x": 0.2211,
          "y": 0.1634
        },
        {
          "x": 0.1156,
          "y": 0.1634
        }
      ],
      "id": 1,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "While our LlamaDuo pipeline presents a promising\nsolution for migrating capabilities from service-\noriented LLMs to smaller local models, as de-\npicted in Table 1, several limitations must be\nacknowledged. First, the reliance on synthetic\ndatasets generated by the service LLM may in-\ntroduce biases and safety issues inherent in the\noriginal model, potentially affecting the fine-tuned\nmodel\u2019s performance on specific tasks or datasets\n(Liu et al., 2024). Additionally, the effectiveness of\nthe pipeline in transferring knowledge is contingent\nupon the quality and diversity of the synthetic data\ngenerated. If the data does not adequately cover the\nnecessary scope, the fine-tuned model may strug-\ngle with tasks outside of the provided examples\n(Razeghi et al., 2022; Kandpal et al., 2023). Fur-\nthermore, the iterative fine-tuning process, while\nbeneficial for performance enhancement, can be\ncomputationally intensive and time-consuming, po-\ntentially offsetting some gains in model efficiency,\ncost, and affordability. Another limitation is the\npotential plateau in performance gains after several\nSFT iterations, which could necessitate alternative\nstrategies for further improvement, e.g., reinforce-\nment learning (RL) (Ouyang et al., 2022; Rafailov\net al., 2023). Lastly, the pipeline assumes access\nto the service LLM for data generation, which may\nnot always be feasible due to proprietary restric-\ntions or API access limitations.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1164,
          "y": 0.1745
        },
        {
          "x": 0.4898,
          "y": 0.1745
        },
        {
          "x": 0.4898,
          "y": 0.6417
        },
        {
          "x": 0.1164,
          "y": 0.6417
        }
      ],
      "id": 2,
      "page": 1
    },
    {
      "category": "heading1",
      "content": {
        "html": "",
        "markdown": "# Ethical Considerations",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1164,
          "y": 0.6542
        },
        {
          "x": 0.3176,
          "y": 0.6542
        },
        {
          "x": 0.3176,
          "y": 0.6698
        },
        {
          "x": 0.1164,
          "y": 0.6698
        }
      ],
      "id": 3,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Our work introduces several ethical considerations\nthat require careful examination. Primarily, the pro-\ncess of generating synthetic datasets raises ques-\ntions about data privacy and security, especially if\nthe data contains sensitive or proprietary informa-\ntion. There is a risk that such data, if not properly\nanonymized and secured, could lead to privacy vi-\nolations or unauthorized data exposure (Liu et al.,\n2024; Das et al., 2025). Moreover, the transfer of\nbiases from the service LLM to the smaller model\ncould perpetuate or even exacerbate existing biases,\nleading to unfair or discriminatory outcomes in cer-\ntain applications. It is crucial to implement robust\nbias detection and mitigation strategies within the\npipeline to safeguard against these risks. Addition-",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1159,
          "y": 0.6808
        },
        {
          "x": 0.4909,
          "y": 0.6808
        },
        {
          "x": 0.4909,
          "y": 0.9236
        },
        {
          "x": 0.1159,
          "y": 0.9236
        }
      ],
      "id": 4,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "ally, the use of proprietary models for generating\nsynthetic data necessitates transparency regarding\ndata handling practices and the potential limitations\nof the resultant models (Wang et al., 2023b).",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5113,
          "y": 0.0858
        },
        {
          "x": 0.8843,
          "y": 0.0858
        },
        {
          "x": 0.8843,
          "y": 0.15
        },
        {
          "x": 0.5113,
          "y": 0.15
        }
      ],
      "id": 5,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Broader Impact",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.512,
          "y": 0.1623
        },
        {
          "x": 0.6543,
          "y": 0.1623
        },
        {
          "x": 0.6543,
          "y": 0.179
        },
        {
          "x": 0.512,
          "y": 0.179
        }
      ],
      "id": 6,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Beyond the immediate focus of this paper, we\nbelieve that the introduction of the LlamaDuo\npipeline has the potential to significantly impact\nthe landscape of LLMs deployment, particularly in\nenvironments with constrained resources or strin-\ngent privacy requirements. By enabling the mi-\ngration of capabilities from large service-oriented\nLLMs to smaller, locally manageable models,\nthe pipeline empowers organizations to maintain\nLLMs functionalities independently of external ser-\nvice providers, enhancing operational resilience\nand reducing dependency. This can lead to in-\ncreased accessibility to advanced LLMs for smaller\nentities or those operating in regions with limited\ninternet connectivity.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5112,
          "y": 0.1882
        },
        {
          "x": 0.8854,
          "y": 0.1882
        },
        {
          "x": 0.8854,
          "y": 0.4293
        },
        {
          "x": 0.5112,
          "y": 0.4293
        }
      ],
      "id": 7,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Acknowledgements",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5126,
          "y": 0.4418
        },
        {
          "x": 0.6827,
          "y": 0.4418
        },
        {
          "x": 0.6827,
          "y": 0.4581
        },
        {
          "x": 0.5126,
          "y": 0.4581
        }
      ],
      "id": 8,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Jing Tang\u2019s work is partially supported by Na-\ntional Key R&D Program of China under Grant\nNo. 2024YFA1012700 and No. 2023YFF0725100,\nby the National Natural Science Foundation of\nChina (NSFC) under Grant No. 62402410 and\nNo. U22B2060, by Guangdong Provincial Project\n(No. 2023QN10X025), by Guangdong Basic and\nApplied Basic Research Foundation under Grant\nNo. 2023A1515110131, by Guangzhou Municipal\nScience and Technology Bureau under Grant No.\n2024A04J4454, by Guangzhou Municipal Educa-\ntion Bureau (No. 2024312263), by Nansha District\nProject (No. 2023ZD022), and by Guangzhou In-\ndustrial Information and Intelligent Key Labora-\ntory Project (No. 2024A03J0628) and Guangzhou\nMunicipal Key Laboratory of Financial Technol-\nogy Cutting-Edge Research (No. 2024A03J0630).\nThis work is supported by IITP grant funded by\nthe Korea government(MSIT)[RS-2023-00215959,\nDevelopment of Access Agnostic wired and wire-\nless integrated optical access technology].",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5113,
          "y": 0.4676
        },
        {
          "x": 0.8864,
          "y": 0.4676
        },
        {
          "x": 0.8864,
          "y": 0.8056
        },
        {
          "x": 0.5113,
          "y": 0.8056
        }
      ],
      "id": 9,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "References",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5113,
          "y": 0.8317
        },
        {
          "x": 0.6106,
          "y": 0.8317
        },
        {
          "x": 0.6106,
          "y": 0.8477
        },
        {
          "x": 0.5113,
          "y": 0.8477
        }
      ],
      "id": 10,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Nazmiye Ceren Abay, Yan Zhou, Murat Kantarcioglu,\nBhavani Thuraisingham, and Latanya Sweeney. 2019.\nPrivacy preserving synthetic data release using deep\nlearning. In Machine Learning and Knowledge\nDiscovery in Databases: European Conference,",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5114,
          "y": 0.8558
        },
        {
          "x": 0.8855,
          "y": 0.8558
        },
        {
          "x": 0.8855,
          "y": 0.922
        },
        {
          "x": 0.5114,
          "y": 0.922
        }
      ],
      "id": 11,
      "page": 1
    }
  ],
  "merged_elements": [],
  "model": "document-parse-250404",
  "ocr": false,
  "usage": {
    "pages": 1
  }
}