{
  "api": "2.0",
  "content": {
    "html": "",
    "markdown": "Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa\nLiu, Noah A Smith, Daniel Khashabi, and Hannaneh\nHajishirzi. 2023b. Self-instruct: Aligning language\nmodels with self-generated instructions. In Proceed-\nings of the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 13484\u201313508.\n\nChenxi Whitehouse, Monojit Choudhury, and Al-\nham Fikri Aji. 2023. LLM-powered data augmenta-\ntion for enhanced cross-lingual performance. In The\n2023 Conference on Empirical Methods in Natural\nLanguage Processing.\n\nXiaodong Wu, Ran Duan, and Jianbing Ni. 2024. Un-\nveiling security, privacy, and ethical concerns of\nchatgpt. Journal of Information and Intelligence,\n2(2):102\u2013115.\n\nCan Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,\nPu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin\nJiang. 2023. Wizardlm: Empowering large lan-\nguage models to follow complex instructions. arXiv\npreprint arXiv:2304.12244.\n\nYiben Yang, Chaitanya Malaviya, Jared Fernandez,\nSwabha Swayamdipta, Ronan Le Bras, Ji-Ping Wang,\nChandra Bhagavatula, Yejin Choi, and Doug Downey.\n2020. Generative data augmentation for common-\nsense reasoning. arXiv preprint arXiv:2004.11546.\n\nKang Min Yoo, Jaegeun Han, Sookyo In, Heewon\nJeon, Jisu Jeong, Jaewook Kang, Hyunwook Kim,\nKyung-Min Kim, Munhyong Kim, Sungju Kim, et al.\n2024. Hyperclova x technical report. arXiv preprint\narXiv:2404.01954.\n\nWeizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho,\nSainbayar Sukhbaatar, Jing Xu, and Jason Weston.\n2024. Self-rewarding language models. arXiv\npreprint arXiv:2401.10020.\n\nShengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang,\nXiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tian-\nwei Zhang, Fei Wu, et al. 2023. Instruction tuning\nfor large language models: A survey. arXiv preprint\narXiv:2308.10792.\n\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,\n\nXiaolei Wang, Yupeng Hou, Yingqian Min, Beichen\n\nZhang, Junjie Zhang, Zican Dong, et al. 2023. A\n\nsurvey of large language models. arXiv preprint\n\narXiv:2303.18223.\n\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\nZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\nZhuohan Li, Dacheng Li, Eric Xing, et al. 2024.\nJudging llm-as-a-judge with mt-bench and chatbot\narena. Advances in Neural Information Processing\nSystems, 36.\n\nChunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer,\nJiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping\nYu, Lili Yu, et al. 2024. Lima: Less is more for align-\nment. Advances in Neural Information Processing\nSystems, 36.",
    "text": ""
  },
  "elements": [
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa\nLiu, Noah A Smith, Daniel Khashabi, and Hannaneh\nHajishirzi. 2023b. Self-instruct: Aligning language\nmodels with self-generated instructions. In Proceed-\nings of the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 13484\u201313508.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1156,
          "y": 0.0864
        },
        {
          "x": 0.4902,
          "y": 0.0864
        },
        {
          "x": 0.4902,
          "y": 0.1785
        },
        {
          "x": 0.1156,
          "y": 0.1785
        }
      ],
      "id": 0,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Chenxi Whitehouse, Monojit Choudhury, and Al-\nham Fikri Aji. 2023. LLM-powered data augmenta-\ntion for enhanced cross-lingual performance. In The\n2023 Conference on Empirical Methods in Natural\nLanguage Processing.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1154,
          "y": 0.1877
        },
        {
          "x": 0.49,
          "y": 0.1877
        },
        {
          "x": 0.49,
          "y": 0.2541
        },
        {
          "x": 0.1154,
          "y": 0.2541
        }
      ],
      "id": 1,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Xiaodong Wu, Ran Duan, and Jianbing Ni. 2024. Un-\nveiling security, privacy, and ethical concerns of\nchatgpt. Journal of Information and Intelligence,\n2(2):102\u2013115.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1154,
          "y": 0.2617
        },
        {
          "x": 0.4898,
          "y": 0.2617
        },
        {
          "x": 0.4898,
          "y": 0.3144
        },
        {
          "x": 0.1154,
          "y": 0.3144
        }
      ],
      "id": 2,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,\nPu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin\nJiang. 2023. Wizardlm: Empowering large lan-\nguage models to follow complex instructions. arXiv\npreprint arXiv:2304.12244.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.118,
          "y": 0.3235
        },
        {
          "x": 0.4886,
          "y": 0.3235
        },
        {
          "x": 0.4886,
          "y": 0.39
        },
        {
          "x": 0.118,
          "y": 0.39
        }
      ],
      "id": 3,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Yiben Yang, Chaitanya Malaviya, Jared Fernandez,\nSwabha Swayamdipta, Ronan Le Bras, Ji-Ping Wang,\nChandra Bhagavatula, Yejin Choi, and Doug Downey.\n2020. Generative data augmentation for common-\nsense reasoning. arXiv preprint arXiv:2004.11546.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1175,
          "y": 0.3982
        },
        {
          "x": 0.4891,
          "y": 0.3982
        },
        {
          "x": 0.4891,
          "y": 0.4655
        },
        {
          "x": 0.1175,
          "y": 0.4655
        }
      ],
      "id": 4,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Kang Min Yoo, Jaegeun Han, Sookyo In, Heewon\nJeon, Jisu Jeong, Jaewook Kang, Hyunwook Kim,\nKyung-Min Kim, Munhyong Kim, Sungju Kim, et al.\n2024. Hyperclova x technical report. arXiv preprint\narXiv:2404.01954.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1162,
          "y": 0.4733
        },
        {
          "x": 0.4888,
          "y": 0.4733
        },
        {
          "x": 0.4888,
          "y": 0.5386
        },
        {
          "x": 0.1162,
          "y": 0.5386
        }
      ],
      "id": 5,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho,\nSainbayar Sukhbaatar, Jing Xu, and Jason Weston.\n2024. Self-rewarding language models. arXiv\npreprint arXiv:2401.10020.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1171,
          "y": 0.5475
        },
        {
          "x": 0.4894,
          "y": 0.5475
        },
        {
          "x": 0.4894,
          "y": 0.6007
        },
        {
          "x": 0.1171,
          "y": 0.6007
        }
      ],
      "id": 6,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang,\nXiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tian-\nwei Zhang, Fei Wu, et al. 2023. Instruction tuning\nfor large language models: A survey. arXiv preprint\narXiv:2308.10792.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1163,
          "y": 0.6093
        },
        {
          "x": 0.4892,
          "y": 0.6093
        },
        {
          "x": 0.4892,
          "y": 0.6748
        },
        {
          "x": 0.1163,
          "y": 0.6748
        }
      ],
      "id": 7,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1174,
          "y": 0.6841
        },
        {
          "x": 0.4895,
          "y": 0.6841
        },
        {
          "x": 0.4895,
          "y": 0.6984
        },
        {
          "x": 0.1174,
          "y": 0.6984
        }
      ],
      "id": 8,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1351,
          "y": 0.6972
        },
        {
          "x": 0.4874,
          "y": 0.6972
        },
        {
          "x": 0.4874,
          "y": 0.7114
        },
        {
          "x": 0.1351,
          "y": 0.7114
        }
      ],
      "id": 9,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Zhang, Junjie Zhang, Zican Dong, et al. 2023. A",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1357,
          "y": 0.7102
        },
        {
          "x": 0.488,
          "y": 0.7102
        },
        {
          "x": 0.488,
          "y": 0.7244
        },
        {
          "x": 0.1357,
          "y": 0.7244
        }
      ],
      "id": 10,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "survey of large language models. arXiv preprint",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1357,
          "y": 0.7229
        },
        {
          "x": 0.4874,
          "y": 0.7229
        },
        {
          "x": 0.4874,
          "y": 0.7374
        },
        {
          "x": 0.1357,
          "y": 0.7374
        }
      ],
      "id": 11,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "arXiv:2303.18223.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1357,
          "y": 0.7359
        },
        {
          "x": 0.2655,
          "y": 0.7359
        },
        {
          "x": 0.2655,
          "y": 0.7504
        },
        {
          "x": 0.1357,
          "y": 0.7504
        }
      ],
      "id": 12,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\nZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\nZhuohan Li, Dacheng Li, Eric Xing, et al. 2024.\nJudging llm-as-a-judge with mt-bench and chatbot\narena. Advances in Neural Information Processing\nSystems, 36.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1153,
          "y": 0.7588
        },
        {
          "x": 0.4886,
          "y": 0.7588
        },
        {
          "x": 0.4886,
          "y": 0.8358
        },
        {
          "x": 0.1153,
          "y": 0.8358
        }
      ],
      "id": 13,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer,\nJiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping\nYu, Lili Yu, et al. 2024. Lima: Less is more for align-\nment. Advances in Neural Information Processing\nSystems, 36.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.115,
          "y": 0.8463
        },
        {
          "x": 0.4892,
          "y": 0.8463
        },
        {
          "x": 0.4892,
          "y": 0.9129
        },
        {
          "x": 0.115,
          "y": 0.9129
        }
      ],
      "id": 14,
      "page": 1
    }
  ],
  "merged_elements": [],
  "model": "document-parse-250404",
  "ocr": false,
  "usage": {
    "pages": 1
  }
}