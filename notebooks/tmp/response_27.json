{
  "api": "2.0",
  "content": {
    "html": "",
    "markdown": "ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference\n\n![image](/image/placeholder)\n- Chart Type: bar\n|  | China | Chinese | Tamil | United States | Latino | d'I | Human Resources | Adhesives | Solvents | Other |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| item_01 | 73.8% | 65.0% | 58.9% | 47.9% | 23.7% | 74.9% | 10.0% | 12.0% | 0.5% | 0.5% |\n\n\nFigure 17: NIAH benchmark for LLaMA-3-8B-Instruct with KV cache size=128 under 8k context length\n\n27",
    "text": ""
  },
  "elements": [
    {
      "category": "header",
      "content": {
        "html": "",
        "markdown": "ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1721,
          "y": 0.0578
        },
        {
          "x": 0.8025,
          "y": 0.0578
        },
        {
          "x": 0.8025,
          "y": 0.072
        },
        {
          "x": 0.1721,
          "y": 0.072
        }
      ],
      "id": 0,
      "page": 1
    },
    {
      "category": "chart",
      "content": {
        "html": "",
        "markdown": "![image](/image/placeholder)\n- Chart Type: bar\n|  | China | Chinese | Tamil | United States | Latino | d'I | Human Resources | Adhesives | Solvents | Other |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| item_01 | 73.8% | 65.0% | 58.9% | 47.9% | 23.7% | 74.9% | 10.0% | 12.0% | 0.5% | 0.5% |\n",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1191,
          "y": 0.0665
        },
        {
          "x": 0.8613,
          "y": 0.0665
        },
        {
          "x": 0.8613,
          "y": 0.8403
        },
        {
          "x": 0.1191,
          "y": 0.8403
        }
      ],
      "id": 1,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Figure 17: NIAH benchmark for LLaMA-3-8B-Instruct with KV cache size=128 under 8k context length",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1408,
          "y": 0.8578
        },
        {
          "x": 0.8351,
          "y": 0.8578
        },
        {
          "x": 0.8351,
          "y": 0.8751
        },
        {
          "x": 0.1408,
          "y": 0.8751
        }
      ],
      "id": 2,
      "page": 1
    },
    {
      "category": "footer",
      "content": {
        "html": "",
        "markdown": "27",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.4765,
          "y": 0.9233
        },
        {
          "x": 0.4983,
          "y": 0.9233
        },
        {
          "x": 0.4983,
          "y": 0.9377
        },
        {
          "x": 0.4765,
          "y": 0.9377
        }
      ],
      "id": 3,
      "page": 1
    }
  ],
  "model": "document-parse-250116",
  "usage": {
    "pages": 1
  }
}