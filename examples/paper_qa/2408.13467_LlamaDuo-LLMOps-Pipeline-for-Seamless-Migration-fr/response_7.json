{
  "api": "2.0",
  "content": {
    "html": "",
    "markdown": "100\n\n![image](/image/placeholder)\nGPT4o Claude3 Sonnet Gemini 1.5 Flash\n80\n80\n7B)\n75\nScore\n60\n60\n(Gemma\n50\nMean\n40 40\nGPT4o\n25 100\n20 20\n0 0 0 50\n1 4 16 64 256\n1 4 16 64 256 1 4 16 64 256 Similarity\n100 0\n100 100\n#50\n0 50\n7B)\n75 Precision\n75 75\n(%)\n(Gemma\n50 50 50\nCoverage\n25 25 25\n0 0 0\n1 4 16 64 256 1 4 16 64 256 1 4 16 64 256\n100 100\n100\n#70\n7B)\n75 75\n75\n(%)\n(Gemma\n50 50 50\nCoverage\n25 25 25\n0 0 0\n1 4 16 64 256 1 4 16 64 256 1 4 16 64 256\nSynthetic Dataset Volume (k)\nPrecision on GPT4o Generated Precision on Claude3 Sonnet Generated Precision on Gemini 1.5 Flash Generated\nSimilarity on GPT4o Generated Similarity on Claude3 Sonnet Generated Similarity on Gemini 1.5 Flash Generated\nPrecision on GPT4o Response Precision on Claude3 Sonnet Response Precision on Gemini 1.5 Flash Response\nSimilarity on GPT4o Response Similarity on Claude3 Sonnet Response Similarity on Gemini 1.5 Flash Response\n\n90\n\nFigure 2: 80 Performance of Gemma 7B fine-tuned on\nvaried volumes of synthetic dataset produced by vari-\n70\nous service LLMs including GPT4o, Claude 3 Sonnet,\n60\nScore\nand Gemini 1.5 Flash. The first to third columns repre-\n50\nMean\nsent the performance of the model evaluated by GPT4o,\n40\nClaude 3 Sonnet, and Gemini 1.5 Flash as judges, re-\n30\nspectively. The first row show mean scores, while the\n20\nsecond and third rows shows the coverage percentage\n10\n1 2 4 8 16 32 64 128 256\nwith 50 and 70 scores, respectively. (k)\nSynthetic Dataset Volume\n\n4.4 In-depth LLMOps Pipeline Analysis\n\nIn this section, we conduct an in-depth analysis\n\nof LlamaDuo through summarization task. No-\n\ntably, the experimental findings exhibit a consistent\npattern across various tasks, underscoring the gen-\neralizability of LlamaDuo.\nImpact of synthetic dataset volume. We explore\nhow the volume of synthetic dataset influences the\nperformances of fine-tuned local LLMs, aiming to\nelucidate a scaling law (Kaplan et al., 2020; Hoff-\nmann et al., 2022) on how the performance of fine-\ntuned models changes as the number of synthetic\ndataset samples increases. Overall, the Gemma 7B\nmodel exhibits consistent performance improve-\nments and comes closer to the performance of ser-\nvice LLMs with increasing volumes of synthetic\ndata, as assessed through precision and similarity\nmetrics by diverse evaluators, as depicted in Figure\n2. This suggests that fine-tuning local LLMs with\nsynthetic data, which mimics the characteristics\nand patterns of real-world data, can bring the same\neffect as actual data. Thus, it paves a new way to\neliminate the challenges of data scarcity, privacy\nconcerns, and high costs associated with crafting\n\n![image](/image/placeholder)\n1k 2k 4k 8k 16k 32k 64k 128k 256k\nGPT4o Claude3 Sonnet Gemini 1.5 Flash\n100 100\n100\n2B)\nSimilarity\n(Gemma\n50 Claude3 Sonnet 50 Gemini 1.5 Flash 50\n100\n100\nSimilarity\n0 0\n50 50 0\n0 Similarity\n0 100 0 0 100 0 100\n0 50 100 0 50 100 100\n100 100 Precision\nPrecision\n7B)\nSimilarity\n(Gemma\n50 50 50\n0 0 0\n0 100 0 100 0 100\nPrecision Precision Precision\n\nFigure 3: The KDE Plots of Precision v.s. Similar-\nity by varied synthetic dataset volumes with 2nk, n \u2208\n{0, 1, . . . , 8} and various evaluators with GPT4o,\nClaude 3 Sonnet, Gemini 1.5 Flash as judges from first\nto third columns, while the first and second rows repre-\nsent the results of Gemma 2B (first row) and Gemma\n7B (second row), respectively.\n\ndata (Liu et al., 2024). Notably, we observe that the\nsynthetic data generated by Claude 3 Sonnet results\nin the highest-performing models, outperforming\nthose fine-tuned with data produced by GPT4o and\nGemini 1.5 Flash, in descending order. Moreover,\nwhen the synthetic dataset volume ranges from 64k\nto 256k, the Gemma 7B model reaches the perfor-\nmance saturation point and achieves performance\nthat is much closer to, or equal to, that of service\nLLMs. This demonstrates the efficacy of our Lla-\nmaDuo in enabling smaller models to replicate or\neven surpass the performance of service LLMs in\nspecific downstream tasks.\n\nImpact of service LLMs as data generator and\njudge. As shown in Figure 2, we observe that the\nchoice of service LLM for data generation does not\nsignificantly impact the performance of the fine-\ntuned models. Specifically, (1) a consistent trend\nof performance enhancement is observed with the\nincreased volume of synthetic data, irrespective\nof the service LLM employed for data generation;\n(2) the local LLMs fine-tuned on synthetic data\ngenerated by GPT4o and Claude3 Sonnet typically\nlead to slightly better performance than those by\nGemini 1.5 Flash. On the other hand, employing\ndifferent service LLMs as judges manifests a more\npronounced impact on the performance of the fine-\ntuned local LLMs. Overall, GPT4o and Gemini\n1.5 Flash emerge as more rigorous judges com-\npared to Claude 3 Sonnet, with Gemini 1.5 Flash\nassigning notably lower similarity scores. More-\nover, we observe that in data sparsity scenarios (1k\nto 4k), the type of evaluators has minimal influ-",
    "text": ""
  },
  "elements": [
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "100",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.4859,
          "y": 0.1854
        },
        {
          "x": 0.4993,
          "y": 0.1854
        },
        {
          "x": 0.4993,
          "y": 0.1908
        },
        {
          "x": 0.4859,
          "y": 0.1908
        }
      ],
      "id": 0,
      "page": 1
    },
    {
      "category": "figure",
      "content": {
        "html": "",
        "markdown": "![image](/image/placeholder)\nGPT4o Claude3 Sonnet Gemini 1.5 Flash\n80\n80\n7B)\n75\nScore\n60\n60\n(Gemma\n50\nMean\n40 40\nGPT4o\n25 100\n20 20\n0 0 0 50\n1 4 16 64 256\n1 4 16 64 256 1 4 16 64 256 Similarity\n100 0\n100 100\n#50\n0 50\n7B)\n75 Precision\n75 75\n(%)\n(Gemma\n50 50 50\nCoverage\n25 25 25\n0 0 0\n1 4 16 64 256 1 4 16 64 256 1 4 16 64 256\n100 100\n100\n#70\n7B)\n75 75\n75\n(%)\n(Gemma\n50 50 50\nCoverage\n25 25 25\n0 0 0\n1 4 16 64 256 1 4 16 64 256 1 4 16 64 256\nSynthetic Dataset Volume (k)\nPrecision on GPT4o Generated Precision on Claude3 Sonnet Generated Precision on Gemini 1.5 Flash Generated\nSimilarity on GPT4o Generated Similarity on Claude3 Sonnet Generated Similarity on Gemini 1.5 Flash Generated\nPrecision on GPT4o Response Precision on Claude3 Sonnet Response Precision on Gemini 1.5 Flash Response\nSimilarity on GPT4o Response Similarity on Claude3 Sonnet Response Similarity on Gemini 1.5 Flash Response",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1124,
          "y": 0.0783
        },
        {
          "x": 0.4926,
          "y": 0.0783
        },
        {
          "x": 0.4926,
          "y": 0.3674
        },
        {
          "x": 0.1124,
          "y": 0.3674
        }
      ],
      "id": 1,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "90",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1855,
          "y": 0.3756
        },
        {
          "x": 0.1933,
          "y": 0.3756
        },
        {
          "x": 0.1933,
          "y": 0.3801
        },
        {
          "x": 0.1855,
          "y": 0.3801
        }
      ],
      "id": 2,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Figure 2: 80 Performance of Gemma 7B fine-tuned on\nvaried volumes of synthetic dataset produced by vari-\n70\nous service LLMs including GPT4o, Claude 3 Sonnet,\n60\nScore\nand Gemini 1.5 Flash. The first to third columns repre-\n50\nMean\nsent the performance of the model evaluated by GPT4o,\n40\nClaude 3 Sonnet, and Gemini 1.5 Flash as judges, re-\n30\nspectively. The first row show mean scores, while the\n20\nsecond and third rows shows the coverage percentage\n10\n1 2 4 8 16 32 64 128 256\nwith 50 and 70 scores, respectively. (k)\nSynthetic Dataset Volume",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1147,
          "y": 0.3844
        },
        {
          "x": 0.49,
          "y": 0.3844
        },
        {
          "x": 0.49,
          "y": 0.5137
        },
        {
          "x": 0.1147,
          "y": 0.5137
        }
      ],
      "id": 3,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "4.4 In-depth LLMOps Pipeline Analysis",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1168,
          "y": 0.5264
        },
        {
          "x": 0.4473,
          "y": 0.5264
        },
        {
          "x": 0.4473,
          "y": 0.5415
        },
        {
          "x": 0.1168,
          "y": 0.5415
        }
      ],
      "id": 4,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "In this section, we conduct an in-depth analysis",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1172,
          "y": 0.5505
        },
        {
          "x": 0.4876,
          "y": 0.5505
        },
        {
          "x": 0.4876,
          "y": 0.5661
        },
        {
          "x": 0.1172,
          "y": 0.5661
        }
      ],
      "id": 5,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "of LlamaDuo through summarization task. No-",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1172,
          "y": 0.5666
        },
        {
          "x": 0.4906,
          "y": 0.5666
        },
        {
          "x": 0.4906,
          "y": 0.5822
        },
        {
          "x": 0.1172,
          "y": 0.5822
        }
      ],
      "id": 6,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "tably, the experimental findings exhibit a consistent\npattern across various tasks, underscoring the gen-\neralizability of LlamaDuo.\nImpact of synthetic dataset volume. We explore\nhow the volume of synthetic dataset influences the\nperformances of fine-tuned local LLMs, aiming to\nelucidate a scaling law (Kaplan et al., 2020; Hoff-\nmann et al., 2022) on how the performance of fine-\ntuned models changes as the number of synthetic\ndataset samples increases. Overall, the Gemma 7B\nmodel exhibits consistent performance improve-\nments and comes closer to the performance of ser-\nvice LLMs with increasing volumes of synthetic\ndata, as assessed through precision and similarity\nmetrics by diverse evaluators, as depicted in Figure\n2. This suggests that fine-tuning local LLMs with\nsynthetic data, which mimics the characteristics\nand patterns of real-world data, can bring the same\neffect as actual data. Thus, it paves a new way to\neliminate the challenges of data scarcity, privacy\nconcerns, and high costs associated with crafting",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1151,
          "y": 0.5748
        },
        {
          "x": 0.4902,
          "y": 0.5748
        },
        {
          "x": 0.4902,
          "y": 0.9255
        },
        {
          "x": 0.1151,
          "y": 0.9255
        }
      ],
      "id": 7,
      "page": 1
    },
    {
      "category": "figure",
      "content": {
        "html": "",
        "markdown": "![image](/image/placeholder)\n1k 2k 4k 8k 16k 32k 64k 128k 256k\nGPT4o Claude3 Sonnet Gemini 1.5 Flash\n100 100\n100\n2B)\nSimilarity\n(Gemma\n50 Claude3 Sonnet 50 Gemini 1.5 Flash 50\n100\n100\nSimilarity\n0 0\n50 50 0\n0 Similarity\n0 100 0 0 100 0 100\n0 50 100 0 50 100 100\n100 100 Precision\nPrecision\n7B)\nSimilarity\n(Gemma\n50 50 50\n0 0 0\n0 100 0 100 0 100\nPrecision Precision Precision",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5118,
          "y": 0.0809
        },
        {
          "x": 0.8856,
          "y": 0.0809
        },
        {
          "x": 0.8856,
          "y": 0.268
        },
        {
          "x": 0.5118,
          "y": 0.268
        }
      ],
      "id": 8,
      "page": 1
    },
    {
      "category": "caption",
      "content": {
        "html": "",
        "markdown": "Figure 3: The KDE Plots of Precision v.s. Similar-\nity by varied synthetic dataset volumes with 2nk, n \u2208\n{0, 1, . . . , 8} and various evaluators with GPT4o,\nClaude 3 Sonnet, Gemini 1.5 Flash as judges from first\nto third columns, while the first and second rows repre-\nsent the results of Gemma 2B (first row) and Gemma\n7B (second row), respectively.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5107,
          "y": 0.2813
        },
        {
          "x": 0.8854,
          "y": 0.2813
        },
        {
          "x": 0.8854,
          "y": 0.3817
        },
        {
          "x": 0.5107,
          "y": 0.3817
        }
      ],
      "id": 9,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "data (Liu et al., 2024). Notably, we observe that the\nsynthetic data generated by Claude 3 Sonnet results\nin the highest-performing models, outperforming\nthose fine-tuned with data produced by GPT4o and\nGemini 1.5 Flash, in descending order. Moreover,\nwhen the synthetic dataset volume ranges from 64k\nto 256k, the Gemma 7B model reaches the perfor-\nmance saturation point and achieves performance\nthat is much closer to, or equal to, that of service\nLLMs. This demonstrates the efficacy of our Lla-\nmaDuo in enabling smaller models to replicate or\neven surpass the performance of service LLMs in\nspecific downstream tasks.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5116,
          "y": 0.3904
        },
        {
          "x": 0.8841,
          "y": 0.3904
        },
        {
          "x": 0.8841,
          "y": 0.5967
        },
        {
          "x": 0.5116,
          "y": 0.5967
        }
      ],
      "id": 10,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Impact of service LLMs as data generator and\njudge. As shown in Figure 2, we observe that the\nchoice of service LLM for data generation does not\nsignificantly impact the performance of the fine-\ntuned models. Specifically, (1) a consistent trend\nof performance enhancement is observed with the\nincreased volume of synthetic data, irrespective\nof the service LLM employed for data generation;\n(2) the local LLMs fine-tuned on synthetic data\ngenerated by GPT4o and Claude3 Sonnet typically\nlead to slightly better performance than those by\nGemini 1.5 Flash. On the other hand, employing\ndifferent service LLMs as judges manifests a more\npronounced impact on the performance of the fine-\ntuned local LLMs. Overall, GPT4o and Gemini\n1.5 Flash emerge as more rigorous judges com-\npared to Claude 3 Sonnet, with Gemini 1.5 Flash\nassigning notably lower similarity scores. More-\nover, we observe that in data sparsity scenarios (1k\nto 4k), the type of evaluators has minimal influ-",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.511,
          "y": 0.5957
        },
        {
          "x": 0.8845,
          "y": 0.5957
        },
        {
          "x": 0.8845,
          "y": 0.9224
        },
        {
          "x": 0.511,
          "y": 0.9224
        }
      ],
      "id": 11,
      "page": 1
    }
  ],
  "merged_elements": [],
  "model": "document-parse-250404",
  "ocr": false,
  "usage": {
    "pages": 1
  }
}