{
  "api": "2.0",
  "content": {
    "html": "",
    "markdown": "ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference\n\n![image](/image/placeholder)\n- Chart Title: LongBench Performance vs Chunk Size\n- X-Axis: Chunk Size\n- Y-Axis: LongBench Score\n- Chart Type: line\n|  | ILaMA-3-BB | Mistral-7B | Owen2-7B | LLaMA-3-BB Full kV | Mistral-7B Full kV | Qwen2-7B Full KV |\n| --- | --- | --- | --- | --- | --- | --- |\n| item_01 | 38 | 46 | 46 | 46 | 46 | 40 |\n\n\nFigure 5: LongBench Performance Comparison with differ-\nent chunk size under 10% compression rate.\n\non index reuse, please refer to the APPENDIX B.1.3.\n\nOverall, these findings on efficiency and performance sug-\ngest that layer-wise index reuse can be an effective technique\nfor optimizing the efficiency-performance trade-off in KV\ncache compression, with the potential for model-specific\ntuning to maximize benefits.\n\n# 5. Ablation study\n\n# 5.1. Chunk Size\n\nThis section aims to investigate the impact of chunk size on\nthe performance of ChunkKV. Different chunk sizes will\nlead to varying degrees of compression on the semantic\ninformation of the data. We set the experiemnt setting the\nsame as in LongBench in Section 4.2. The chunk size is\nset from the range {1, 3, 5, 10, 20, 30}. Figure 5 shows the\nperformance of the ChunkKV with different chunk size on\nthe LongBench and NIAH benchmarks. The three colorful\ncurves represent three LLMs with different chunk sizes, and\nthe colorful dashed line is the corresponding FullKV perfor-\nmance. For more experiments on the size of the chunks with\ndifferent compression ratios, refer to the Appendix B.4.\n\nTable 9: LongBench Performance with Different Chunk\nSizes and Compression Ratios for LLaMA-3-8B-Instruct\n\n| Compression | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| Rate | 1 | 3 | 5 | 10 | 15 | 20 | 30 |\n| 10% | 37.32 | 40.49 | 40.47 | 40.51 | 40.21 | 40.05 | 39.57 |\n| 20% | 38.80 | 40.66 | 40.57 | 40.74 | 40.53 | 40.46 | 40.04 |\n| 30% | 39.23 | 41.02 | 41.29 | 41.59 | 41.38 | 41.33 | 41.02 |\n\n\nFrom Figure 5, we can observe that the LongBench per-\nformance of ChunkKV is not significantly affected by the\nchunk size, with performance variations less than 1%. The\nthree curves are closely aligned, indicating that chunk sizes\nin the range of {10, 20} exhibit better performance.\n\nTable 9 and 10 show the performance of ChunkKV with\ndifferent comperession ratios and different chunk sizes on\nthe LongBench and NIAH. We conducted extensive exper-\niments across different compression ratios and KV cache\nsizes to shows the effectiveness of ChunkKV and the chunk\nsize is robust.\n\nTable 10: NIAH Performance with Different Chunk Sizes\nand KV Cache Sizes for LLaMA-3-8B-Instruct\n\n| KV Cache | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| Size | 1 | 3 | 5 | 10 | 15 | 20 | 30 |\n| 96 | 41.0 | 63.2 | 65.2 | 70.3 | 67.2 | 65.3 | 53.1 |\n| 128 | 47.9 | 65.6 | 69.1 | 73.8 | 72.3 | 72.0 | 71.2 |\n| 256 | 61.7 | 70.3 | 71.2 | 74.1 | 73.2 | 72.3 | 71.1 |\n| 512 | 68.6 | 72.6 | 72.5 | 74.5 | 74.3 | 74.0 | 72.6 |\n\n\nFrom the chunk size ablation study, we can observe that\nacross different tasks (LongBench and NIAH) and vari-\nous compression settings, a chunk size of 10 consistently\ndelivers optimal or near-optimal performance. This em-\npirical finding suggests that a chunk size of 10 strikes a\ngood balance between preserving semantic information and\ncompression efficiency, making it a robust default choice\nfor ChunkKV. Therefore, we adopt this chunk size setting\nthroughout our experiments.\n\n# 6. Conclusion\n\nWe introduced ChunkKV, a novel KV cache compression\nmethod that preserves semantic information by retaining\nmore informative chunks. Through extensive experiments\nacross multiple state-of-the-art LLMs (including DeepSeek-\nR1, LLaMA-3, Qwen2, and Mistral) and diverse bench-\nmarks (GSM8K, LongBench, NIAH, and JailbreakV), we\ndemonstrate that ChunkKV consistently outperforms ex-\nisting methods while using only a fraction of the memory.\nOur comprehensive analysis shows that ChunkKV\u2019s chunk-\nbased approach maintains crucial contextual information,\nleading to superior performance in complex reasoning tasks,\nlong-context understanding, and safety evaluations. The\nmethod\u2019s effectiveness is particularly evident in challenging\nscenarios like many-shot GSM8K and multi-document QA\ntasks, where semantic coherence is crucial. Furthermore,\nour proposed layer-wise index reuse technique provides\nsignificant computational efficiency gains with minimal per-\nformance impact, achieving up to 20.7% latency reduction\nand 26.5% throughput improvement. These findings, sup-\nported by detailed quantitative analysis and ablation stud-\nies, establish ChunkKV as a significant advancement in KV\ncache compression technology, offering an effective solution\nfor deploying LLMs in resource-constrained environments\nwhile maintaining high-quality outputs.\n\n8",
    "text": ""
  },
  "elements": [
    {
      "category": "header",
      "content": {
        "html": "",
        "markdown": "ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.1716,
          "y": 0.0577
        },
        {
          "x": 0.8037,
          "y": 0.0577
        },
        {
          "x": 0.8037,
          "y": 0.0719
        },
        {
          "x": 0.1716,
          "y": 0.0719
        }
      ],
      "id": 0,
      "page": 1
    },
    {
      "category": "chart",
      "content": {
        "html": "",
        "markdown": "![image](/image/placeholder)\n- Chart Title: LongBench Performance vs Chunk Size\n- X-Axis: Chunk Size\n- Y-Axis: LongBench Score\n- Chart Type: line\n|  | ILaMA-3-BB | Mistral-7B | Owen2-7B | LLaMA-3-BB Full kV | Mistral-7B Full kV | Qwen2-7B Full KV |\n| --- | --- | --- | --- | --- | --- | --- |\n| item_01 | 38 | 46 | 46 | 46 | 46 | 40 |\n",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.106,
          "y": 0.087
        },
        {
          "x": 0.4541,
          "y": 0.087
        },
        {
          "x": 0.4541,
          "y": 0.2797
        },
        {
          "x": 0.106,
          "y": 0.2797
        }
      ],
      "id": 1,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Figure 5: LongBench Performance Comparison with differ-\nent chunk size under 10% compression rate.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.0874,
          "y": 0.2935
        },
        {
          "x": 0.4773,
          "y": 0.2935
        },
        {
          "x": 0.4773,
          "y": 0.325
        },
        {
          "x": 0.0874,
          "y": 0.325
        }
      ],
      "id": 2,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "on index reuse, please refer to the APPENDIX B.1.3.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.0879,
          "y": 0.3425
        },
        {
          "x": 0.4392,
          "y": 0.3425
        },
        {
          "x": 0.4392,
          "y": 0.3569
        },
        {
          "x": 0.0879,
          "y": 0.3569
        }
      ],
      "id": 3,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Overall, these findings on efficiency and performance sug-\ngest that layer-wise index reuse can be an effective technique\nfor optimizing the efficiency-performance trade-off in KV\ncache compression, with the potential for model-specific\ntuning to maximize benefits.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.088,
          "y": 0.3652
        },
        {
          "x": 0.4773,
          "y": 0.3652
        },
        {
          "x": 0.4773,
          "y": 0.4406
        },
        {
          "x": 0.088,
          "y": 0.4406
        }
      ],
      "id": 4,
      "page": 1
    },
    {
      "category": "heading1",
      "content": {
        "html": "",
        "markdown": "# 5. Ablation study",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.0873,
          "y": 0.4596
        },
        {
          "x": 0.2346,
          "y": 0.4596
        },
        {
          "x": 0.2346,
          "y": 0.4762
        },
        {
          "x": 0.0873,
          "y": 0.4762
        }
      ],
      "id": 5,
      "page": 1
    },
    {
      "category": "heading1",
      "content": {
        "html": "",
        "markdown": "# 5.1. Chunk Size",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.0876,
          "y": 0.4856
        },
        {
          "x": 0.2025,
          "y": 0.4856
        },
        {
          "x": 0.2025,
          "y": 0.5005
        },
        {
          "x": 0.0876,
          "y": 0.5005
        }
      ],
      "id": 6,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "This section aims to investigate the impact of chunk size on\nthe performance of ChunkKV. Different chunk sizes will\nlead to varying degrees of compression on the semantic\ninformation of the data. We set the experiemnt setting the\nsame as in LongBench in Section 4.2. The chunk size is\nset from the range {1, 3, 5, 10, 20, 30}. Figure 5 shows the\nperformance of the ChunkKV with different chunk size on\nthe LongBench and NIAH benchmarks. The three colorful\ncurves represent three LLMs with different chunk sizes, and\nthe colorful dashed line is the corresponding FullKV perfor-\nmance. For more experiments on the size of the chunks with\ndifferent compression ratios, refer to the Appendix B.4.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.0882,
          "y": 0.5087
        },
        {
          "x": 0.4763,
          "y": 0.5087
        },
        {
          "x": 0.4763,
          "y": 0.6902
        },
        {
          "x": 0.0882,
          "y": 0.6902
        }
      ],
      "id": 7,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Table 9: LongBench Performance with Different Chunk\nSizes and Compression Ratios for LLaMA-3-8B-Instruct",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.0873,
          "y": 0.7016
        },
        {
          "x": 0.4754,
          "y": 0.7016
        },
        {
          "x": 0.4754,
          "y": 0.7327
        },
        {
          "x": 0.0873,
          "y": 0.7327
        }
      ],
      "id": 8,
      "page": 1
    },
    {
      "category": "table",
      "content": {
        "html": "",
        "markdown": "| Compression | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| Rate | 1 | 3 | 5 | 10 | 15 | 20 | 30 |\n| 10% | 37.32 | 40.49 | 40.47 | 40.51 | 40.21 | 40.05 | 39.57 |\n| 20% | 38.80 | 40.66 | 40.57 | 40.74 | 40.53 | 40.46 | 40.04 |\n| 30% | 39.23 | 41.02 | 41.29 | 41.59 | 41.38 | 41.33 | 41.02 |\n",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.0908,
          "y": 0.7448
        },
        {
          "x": 0.4754,
          "y": 0.7448
        },
        {
          "x": 0.4754,
          "y": 0.8199
        },
        {
          "x": 0.0908,
          "y": 0.8199
        }
      ],
      "id": 9,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "From Figure 5, we can observe that the LongBench per-\nformance of ChunkKV is not significantly affected by the\nchunk size, with performance variations less than 1%. The\nthree curves are closely aligned, indicating that chunk sizes\nin the range of {10, 20} exhibit better performance.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.0883,
          "y": 0.8321
        },
        {
          "x": 0.4763,
          "y": 0.8321
        },
        {
          "x": 0.4763,
          "y": 0.908
        },
        {
          "x": 0.0883,
          "y": 0.908
        }
      ],
      "id": 10,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Table 9 and 10 show the performance of ChunkKV with\ndifferent comperession ratios and different chunk sizes on\nthe LongBench and NIAH. We conducted extensive exper-\niments across different compression ratios and KV cache\nsizes to shows the effectiveness of ChunkKV and the chunk\nsize is robust.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.4991,
          "y": 0.0861
        },
        {
          "x": 0.8902,
          "y": 0.0861
        },
        {
          "x": 0.8902,
          "y": 0.1761
        },
        {
          "x": 0.4991,
          "y": 0.1761
        }
      ],
      "id": 11,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "Table 10: NIAH Performance with Different Chunk Sizes\nand KV Cache Sizes for LLaMA-3-8B-Instruct",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.4978,
          "y": 0.1984
        },
        {
          "x": 0.8884,
          "y": 0.1984
        },
        {
          "x": 0.8884,
          "y": 0.2288
        },
        {
          "x": 0.4978,
          "y": 0.2288
        }
      ],
      "id": 12,
      "page": 1
    },
    {
      "category": "table",
      "content": {
        "html": "",
        "markdown": "| KV Cache | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size | Chunk Size |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| Size | 1 | 3 | 5 | 10 | 15 | 20 | 30 |\n| 96 | 41.0 | 63.2 | 65.2 | 70.3 | 67.2 | 65.3 | 53.1 |\n| 128 | 47.9 | 65.6 | 69.1 | 73.8 | 72.3 | 72.0 | 71.2 |\n| 256 | 61.7 | 70.3 | 71.2 | 74.1 | 73.2 | 72.3 | 71.1 |\n| 512 | 68.6 | 72.6 | 72.5 | 74.5 | 74.3 | 74.0 | 72.6 |\n",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.5026,
          "y": 0.242
        },
        {
          "x": 0.8874,
          "y": 0.242
        },
        {
          "x": 0.8874,
          "y": 0.3422
        },
        {
          "x": 0.5026,
          "y": 0.3422
        }
      ],
      "id": 13,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "From the chunk size ablation study, we can observe that\nacross different tasks (LongBench and NIAH) and vari-\nous compression settings, a chunk size of 10 consistently\ndelivers optimal or near-optimal performance. This em-\npirical finding suggests that a chunk size of 10 strikes a\ngood balance between preserving semantic information and\ncompression efficiency, making it a robust default choice\nfor ChunkKV. Therefore, we adopt this chunk size setting\nthroughout our experiments.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.4995,
          "y": 0.3635
        },
        {
          "x": 0.8906,
          "y": 0.3635
        },
        {
          "x": 0.8906,
          "y": 0.4998
        },
        {
          "x": 0.4995,
          "y": 0.4998
        }
      ],
      "id": 14,
      "page": 1
    },
    {
      "category": "heading1",
      "content": {
        "html": "",
        "markdown": "# 6. Conclusion",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.4992,
          "y": 0.5181
        },
        {
          "x": 0.6179,
          "y": 0.5181
        },
        {
          "x": 0.6179,
          "y": 0.5347
        },
        {
          "x": 0.4992,
          "y": 0.5347
        }
      ],
      "id": 15,
      "page": 1
    },
    {
      "category": "paragraph",
      "content": {
        "html": "",
        "markdown": "We introduced ChunkKV, a novel KV cache compression\nmethod that preserves semantic information by retaining\nmore informative chunks. Through extensive experiments\nacross multiple state-of-the-art LLMs (including DeepSeek-\nR1, LLaMA-3, Qwen2, and Mistral) and diverse bench-\nmarks (GSM8K, LongBench, NIAH, and JailbreakV), we\ndemonstrate that ChunkKV consistently outperforms ex-\nisting methods while using only a fraction of the memory.\nOur comprehensive analysis shows that ChunkKV\u2019s chunk-\nbased approach maintains crucial contextual information,\nleading to superior performance in complex reasoning tasks,\nlong-context understanding, and safety evaluations. The\nmethod\u2019s effectiveness is particularly evident in challenging\nscenarios like many-shot GSM8K and multi-document QA\ntasks, where semantic coherence is crucial. Furthermore,\nour proposed layer-wise index reuse technique provides\nsignificant computational efficiency gains with minimal per-\nformance impact, achieving up to 20.7% latency reduction\nand 26.5% throughput improvement. These findings, sup-\nported by detailed quantitative analysis and ablation stud-\nies, establish ChunkKV as a significant advancement in KV\ncache compression technology, offering an effective solution\nfor deploying LLMs in resource-constrained environments\nwhile maintaining high-quality outputs.",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.4996,
          "y": 0.5441
        },
        {
          "x": 0.8916,
          "y": 0.5441
        },
        {
          "x": 0.8916,
          "y": 0.9081
        },
        {
          "x": 0.4996,
          "y": 0.9081
        }
      ],
      "id": 16,
      "page": 1
    },
    {
      "category": "footer",
      "content": {
        "html": "",
        "markdown": "8",
        "text": ""
      },
      "coordinates": [
        {
          "x": 0.4808,
          "y": 0.9245
        },
        {
          "x": 0.4941,
          "y": 0.9245
        },
        {
          "x": 0.4941,
          "y": 0.9372
        },
        {
          "x": 0.4808,
          "y": 0.9372
        }
      ],
      "id": 17,
      "page": 1
    }
  ],
  "model": "document-parse-250116",
  "usage": {
    "pages": 1
  }
}